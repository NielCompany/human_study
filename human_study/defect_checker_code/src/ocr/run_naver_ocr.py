# ì‚¬ì§„ì„ ë¶ˆëŸ¬ì˜¤ê³  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ(easyocr ì‚¬ìš©)í•´ì„œ jsoníŒŒì¼ë¡œ ì €ì¥ 
import requests
import os
import uuid
import time
import json
from pathlib import Path
from collections import OrderedDict
from tqdm import tqdm
from dotenv import load_dotenv

load_dotenv()
CLOBA_API_KEY = os.getenv("CLOBA_API_KEY")

# âœ… CLOVA OCR ì„¤ì •
API_URL = 'https://2cphq1vxd0.apigw.ntruss.com/custom/v1/42151/a1af5c2a61e3b09e3f2d750b86dd3d4b58e873f8a3bcdbe138c95b6d24e5cc7c/general'  # ì‹¤ì œ ê°’ìœ¼ë¡œ êµì²´
SECRET_KEY = CLOBA_API_KEY  # ì‹¤ì œ í‚¤ë¡œ êµì²´
INPUT_DIR = Path("data/samples3")
OUTPUT_DIR = Path("data/ocr_texts3")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# âœ… í‚¤ì›Œë“œ ì •ì˜ ë° í‘œì¤€í™”
KEYWORDS = ["í˜„ì¥ëª…", "ê³µì¢…", "ìœ„ì¹˜", "ë‚´ìš©", "ì¼ì", "ê¸°íƒ€", "ìƒì„¸ë‚´ìš©"]
KEYWORD_ALIASES = {
    "ê³µì‚¬ëª…": "í˜„ì¥ëª…",
    "ê³µ ì¢…": "ê³µì¢…",
    "ê³µì¢…": "ê³µì¢…",
    "ìœ„ ì¹˜": "ìœ„ì¹˜",
    "ìœ„ì¹˜": "ìœ„ì¹˜",
    "ë‚´ ìš©": "ë‚´ìš©",
    "ë‚´ìš©": "ë‚´ìš©",
    "ì¼ ì": "ì¼ì",
    "ì¼ì": "ì¼ì",
    "ê¸°íƒ€": "ê¸°íƒ€",
    "ìƒì„¸ ë‚´ìš©": "ìƒì„¸ë‚´ìš©"
}

def normalize_keyword(keyword: str) -> str:
    return KEYWORD_ALIASES.get(keyword.replace(" ", ""), keyword.replace(" ", ""))

def run_ocr(image_path: Path):
    request_json = {
        'images': [{'format': image_path.suffix[1:], 'name': image_path.name}],
        'requestId': str(uuid.uuid4()),
        'version': 'V2',
        'timestamp': int(round(time.time() * 1000))
    }
    payload = {'message': json.dumps(request_json).encode('UTF-8')}
    files = [('file', open(image_path, 'rb'))]
    headers = {'X-OCR-SECRET': SECRET_KEY}

    try:
        response = requests.post(API_URL, headers=headers, data=payload, files=files, timeout=30)
        return response.json()
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {image_path.name} - {e}")
        return None

def parse_ocr_response(result_json):
    texts = [f['inferText'].strip() for f in result_json['images'][0]['fields']]
    output = OrderedDict()
    current_key = None
    ë™í˜¸ìˆ˜ = ""

    for text in texts:
        norm_text = normalize_keyword(text)
        if norm_text in KEYWORDS:
            current_key = norm_text
            output[current_key] = ""
        elif "ë™" in text and "í˜¸" in text and current_key == "í˜„ì¥ëª…":
            ë™í˜¸ìˆ˜ = text
        elif current_key:
            output[current_key] += text + " "

    if "í˜„ì¥ëª…" in output and ë™í˜¸ìˆ˜:
        output["í˜„ì¥ëª…"] = output["í˜„ì¥ëª…"].strip() + " " + ë™í˜¸ìˆ˜

    return {k: v.strip() for k, v in output.items()}

def main():
    image_paths = sorted([p for p in INPUT_DIR.glob("*") if p.suffix.lower() in [".jpg", ".jpeg", ".png"]])

    for img_path in tqdm(image_paths, desc="ğŸ” OCR ì§„í–‰ ì¤‘"):
        result_json = run_ocr(img_path)
        if result_json:
            parsed = parse_ocr_response(result_json)
            save_path = OUTPUT_DIR / f"{img_path.stem}.json"
            with open(save_path, 'w', encoding='utf-8') as f:
                json.dump({
                    "image": img_path.name,
                    "fields": parsed,
                    "raw": result_json['images'][0]['fields']
                }, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    main()